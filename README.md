# Employee Attrition Prediction: Explainable Machine Learning Report

This project applies interpretable machine learning techniques to predict employee attrition using logistic regression, with a focus on transparency and stakeholder communication. Both **global** and **local** model explanations are included, leveraging model coefficients and SHAP values.

---

## Objective

Predict which employees are at risk of leaving the company and understand *why*, using:

- **Logistic Regression** for interpretability.
- **SHAP Values** for individualized explanations and global patterns.
- A structured, end-to-end ML pipeline with preprocessing and evaluation.

---

## 1. Logistic Regression Coefficients (Global Explainability)

Logistic regression provides a direct mapping between feature values and their contribution to the log-odds of attrition.

- Positive coefficients increase attrition risk.
- Negative coefficients reduce it.

### Key Highlights

- **Strongest Positive Predictors**:  
  `EducationField_Technical Degree`, `JobRole_Research Scientist`, and `BusinessTravel_Non-Travel`.

- **Strongest Negative Predictors**:  
  `JobRole_Healthcare Representative`, `JobRole_Manager`, and `BusinessTravel_Travel_Rarely`.

- **Minimal Impact Features**:  
  Features like `Gender`, `Education`, and `JobRole_Human Resources` showed negligible coefficient values.

### [Insert Coefficients Bar Chart Here]

---

## 2. SHAP Value Interpretation (Global + Local Explainability)

SHAP values explain predictions on a per-observation basis and provide model-agnostic insights.

- Each dot shows how a feature contributed to an individual prediction.
- Color indicates feature value (blue = low, red = high).
- Horizontal position reflects direction/magnitude of influence.

### Key Global Insights (SHAP)

- **Most Influential Features**:  
  `NumCompaniesWorked`, `TotalWorkingYears`, `YearsWithCurrManager`, and `EnvironmentSatisfaction`.

- **Contrast With Coefficients**:  
  Some features with low coefficients (e.g. `NumCompaniesWorked`) had high SHAP impactâ€”emphasizing their interaction effects or conditional relevance.

### [Insert SHAP Summary Plot Here]  
### [Insert SHAP Beeswarm Plot Here]

---

## 3. Final Thoughts

- Coefficients tell us how the model is built.
- SHAP tells us how the model behaves.
- Together, they give a full picture: the "rules" (coefficients) and the "realities" (SHAP).

This project demonstrates the value of combining linear interpretability with model-agnostic explanation tools to surface actionable insights in HR analytics.

---

## ğŸ”§ Repository Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ final_model_pipeline.pkl
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_modeling.ipynb
â”‚   â”œâ”€â”€ 04_explainability.ipynb
â”‚   â””â”€â”€ 05_final_report.ipynb
â””â”€â”€ README.md
```

---

## ğŸ” Next Steps

- Add SHAP-based cohort profiling for team-level analysis.
- Implement visual dashboards using Streamlit or Tableau.
- Extend analysis with Random Forest or XGBoost for performance benchmarking.

