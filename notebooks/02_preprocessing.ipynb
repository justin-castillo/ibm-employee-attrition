{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b5cf274",
   "metadata": {},
   "source": [
    "# **Preprocessing**\n",
    "\n",
    "## Notebook overview\n",
    "\n",
    "---\n",
    "\n",
    "This notebook alters the features to best capture the true nature of the data, based on the insights from the previous notebook. To do this, we define a class the encapsulates all of this logic, then wrap it in a reusable pipeline to ensure that there is no data leakage throughout the modeling process. \n",
    "\n",
    "Tasks: \n",
    "\n",
    "- Apply custom feature engineering logic (`FeatureEngineer`) to extract meaningful patterns.\n",
    "- Encode categorical variables using one-hot encoding.\n",
    "- Scale numeric features to help stabilize logistic regression modeling.\n",
    "- Combine all preprocessing steps into a single `Pipeline` object.\n",
    "- Save the full pipeline with `joblib` so we can apply it consistently later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e44762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing environment initialized.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')  \n",
    "from feature_engineering import FeatureEngineer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Preprocessing environment initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6e0ee",
   "metadata": {},
   "source": [
    "## 1. Reload data\n",
    "\n",
    "---\n",
    "\n",
    "We reload the cleaned dataset (data_01.csv) and validate that all expected columns are present — no extras, none missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2015a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column schema validation passed.\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_csv('../data/processed/data_01.csv')\n",
    "\n",
    "# Define expected column names after EDA cleanup\n",
    "expected_columns = [\n",
    "    'Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "    'DistanceFromHome', 'Education', 'EducationField', 'EnvironmentSatisfaction',\n",
    "    'Gender', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
    "    'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
    "    'NumCompaniesWorked', 'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
    "    'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears',\n",
    "    'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany',\n",
    "    'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'\n",
    "]\n",
    "\n",
    "# Get actual columns from the loaded DataFrame\n",
    "actual_columns = list(df.columns)\n",
    "\n",
    "# Compare against expected\n",
    "missing_columns = set(expected_columns) - set(actual_columns)\n",
    "unexpected_columns = set(actual_columns) - set(expected_columns)\n",
    "\n",
    "# Display results\n",
    "if not missing_columns and not unexpected_columns:\n",
    "    print(\"Column schema validation passed.\")\n",
    "else:\n",
    "    if missing_columns:\n",
    "        print(\"Missing columns:\", missing_columns)\n",
    "    if unexpected_columns:\n",
    "        print(\"Unexpected columns:\", unexpected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e977d",
   "metadata": {},
   "source": [
    "## 2. Validation\n",
    "\n",
    "---\n",
    "\n",
    "Before preprocessing, we run validations to ensure:\n",
    "- No missing values or constant columns remain\n",
    "- Correct data types \n",
    "- Target (Attrition) is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279be89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found.\n",
      "\n",
      "Data types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age                          int64\n",
       "Attrition                   object\n",
       "BusinessTravel              object\n",
       "DailyRate                    int64\n",
       "Department                  object\n",
       "DistanceFromHome             int64\n",
       "Education                    int64\n",
       "EducationField              object\n",
       "EnvironmentSatisfaction      int64\n",
       "Gender                      object\n",
       "HourlyRate                   int64\n",
       "JobInvolvement               int64\n",
       "JobLevel                     int64\n",
       "JobRole                     object\n",
       "JobSatisfaction              int64\n",
       "MaritalStatus               object\n",
       "MonthlyIncome                int64\n",
       "MonthlyRate                  int64\n",
       "NumCompaniesWorked           int64\n",
       "OverTime                    object\n",
       "PercentSalaryHike            int64\n",
       "PerformanceRating            int64\n",
       "RelationshipSatisfaction     int64\n",
       "StockOptionLevel             int64\n",
       "TotalWorkingYears            int64\n",
       "TrainingTimesLastYear        int64\n",
       "WorkLifeBalance              int64\n",
       "YearsAtCompany               int64\n",
       "YearsInCurrentRole           int64\n",
       "YearsSinceLastPromotion      int64\n",
       "YearsWithCurrManager         int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constant columns detected.\n",
      "\n",
      "Class balance in 'Attrition':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Attrition\n",
       "No     0.839\n",
       "Yes    0.161\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for nulls (none expected)\n",
    "null_counts = df.isnull().sum()\n",
    "if null_counts.any():\n",
    "    print(\"Unexpected null values found:\")\n",
    "    display(null_counts[null_counts > 0])\n",
    "else:\n",
    "    print(\"No null values found.\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "display(df.dtypes)\n",
    "\n",
    "# Identify constant columns\n",
    "nunique = df.nunique()\n",
    "constant_cols = nunique[nunique == 1].index.tolist()\n",
    "\n",
    "if constant_cols:\n",
    "    print(f\"Constant columns detected and dropped: {constant_cols}\")\n",
    "    df.drop(columns=constant_cols, inplace=True)\n",
    "    print(f\"New shape after dropping: {df.shape}\")\n",
    "else:\n",
    "    print(\"No constant columns detected.\")\n",
    "\n",
    "# Confirm target variable distribution\n",
    "print(\"\\nClass balance in 'Attrition':\")\n",
    "display(df['Attrition'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe07bf8",
   "metadata": {},
   "source": [
    "## 3. Feature engineering pipeline\n",
    "\n",
    "---\n",
    "\n",
    "- This section creates custom features to capture patterns not directly visible in the raw data. We encapsulate this logic inside of a class, `FeatureEngineer()`, and then merge this into a Pipeline to prevent data leakage and ensure consistent preprocessing steps are applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c88658",
   "metadata": {},
   "source": [
    "### `FeatureEngineer()` and `make_preprocessing_pipeline`\n",
    "\n",
    "To capture interactions between features, and to make features suitable for modeling, all feature engineering logic is placed inside of class FeatureEngineer. This is helpful because it avoids having to repeat logic in subsequent notebooks. \n",
    "\n",
    "Below is a breakdown of each added/modified feature:\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Tenure and experience features\n",
    "\n",
    "**`TenureCategory`**  \n",
    "Buckets `YearsAtCompany` into tenure groups:  \n",
    "- `0–3 yrs`  \n",
    "- `4–6 yrs`  \n",
    "- `7–10 yrs`  \n",
    "- `10+ yrs`  \n",
    "This captures key career stage segments, which may correspond to different attrition risks.\n",
    "\n",
    "**`TenureGap`**  \n",
    "Calculates: `YearsInCurrentRole` − `YearsAtCompany`  \n",
    "Employees who may have changed roles internally versus those who stayed static, potentially indicating engagement or stagnation.\n",
    "\n",
    "**`TenureRatio`**  \n",
    "Calculates: `YearsInCurrentRole` / `YearsAtCompany`  \n",
    "Identify fast or slow transitions. High ratios may indicate stagnation, while low ratios may indicate fast promotions or instability.\n",
    "\n",
    "**`ZeroCompanyTenureFlag`**  \n",
    "Binary flag indicating `YearsAtCompany` == 0  \n",
    "Captures newly joined employees who may behave differently.\n",
    "\n",
    "**`NewJoinerFlag`**  \n",
    "Flags employees with:\n",
    "- `YearsAtCompany` < 2  \n",
    "- `TotalWorkingYears` > 3  \n",
    "These are experienced employees that recently joined - a group that may behave differently due to habits or philosophies from previous jobs. \n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Role and work features\n",
    "\n",
    "**`Overtime_JobLevel`**  \n",
    "Interaction between `OverTime` and `JobLevel`  \n",
    "Useful for identifying levels of staff that are potentially overworked.\n",
    "\n",
    "**`Travel_Occupation`**  \n",
    "Combined effect of travel frequency and job role.  \n",
    "Identify roles with high levels of travel which correlates with elevated attrition risk. \n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Satisfaction features\n",
    "\n",
    "**`SatisfactionMean`**  \n",
    "Averages the satisfaction scores:  \n",
    "- `EnvironmentSatisfaction`  \n",
    "- `JobSatisfaction`  \n",
    "- `RelationshipSatisfaction`  \n",
    "Provides a general overview of employee sentiment.\n",
    "\n",
    "**`SatisfactionRange`**  \n",
    "Calculates range of the 3 satisfaction scores  \n",
    "Inconsistency in perceived satisfaction, potentially indicating internal conflict or instability.\n",
    "\n",
    "**`SatisfactionStability`**  \n",
    "Binary flag: 1 if all 3 satisfaction scores are equal  \n",
    "Identifies employees with consistent satisfaction levels across all domains.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Financial features\n",
    "\n",
    "**`Log_MonthlyIncome`**  \n",
    "Applies log transform to `MonthlyIncome`  \n",
    "Reduce skew and compress extreme values.\n",
    "\n",
    "**`Log_DistanceFromHome`**  \n",
    "Applies log transform to `DistanceFromHome`  \n",
    "Reduce skew and compress extreme values.\n",
    "\n",
    "**`LowIncomeFlag`**  \n",
    "Binary flag for employees earning below the 25th percentile of income  \n",
    "Captures possible financial dissatisfaction.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Burnout risk\n",
    "\n",
    "**`StressRisk`**  \n",
    "Binary flag for employees where:  \n",
    "- `OverTime` == Yes  \n",
    "- `JobSatisfaction` ≤ 2  \n",
    "- `SatisfactionMean` < 2.5  \n",
    "Combines workload and dissatisfaction into a high-risk signal for possible voluntary attrition.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c70b1cf",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline definition\n",
    "\n",
    "We finalize the preprocessing logic here by defining which columns to encode, scale, or pass through unchanged:\n",
    "\n",
    "- Categorical variables are one-hot encoded.\n",
    "- Continuous numeric features are standardized with `StandardScaler`.\n",
    "- Binary flags from feature engineering are passed through untouched.\n",
    "- All transformations are bundled into a `ColumnTransformer`, which is embedded in a reusable `Pipeline`.\n",
    "\n",
    "This pipeline will be saved and applied during modeling (`03_modeling.ipynb`) to ensure consistent preprocessing and no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd53c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "def make_preprocessing_pipeline():\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    nominal_cols = [\n",
    "        'Department', 'EducationField', 'Gender', 'MaritalStatus',\n",
    "        'OverTime', 'TenureCategory', 'OverTime_JobLevel', 'Travel_Occupation'\n",
    "    ]\n",
    "\n",
    "    # Standardize continuous features \n",
    "    scale_cols = [\n",
    "        'Age', 'DistanceFromHome', 'HourlyRate', 'JobInvolvement', 'JobLevel',\n",
    "        'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
    "        'PerformanceRating', 'StockOptionLevel', 'TotalWorkingYears',\n",
    "        'TrainingTimesLastYear',\n",
    "        'YearsSinceLastPromotion', 'YearsWithCurrManager',\n",
    "        'TenureRatio', 'TenureGap', 'SatisfactionMean', 'SatisfactionRange',\n",
    "        'PromotionPerYear', 'YearsCompany_Satisfaction',\n",
    "        'Log_MonthlyIncome', 'Log_DistanceFromHome'\n",
    "    ]\n",
    "\n",
    "    # Pass through binary flags\n",
    "    passthrough_cols = [\n",
    "        'ZeroCompanyTenureFlag', 'NewJoinerFlag', 'LowIncomeFlag',\n",
    "        'SatisfactionStability', 'StressRisk'\n",
    "    ]\n",
    "\n",
    "    # Build column transformer\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('nominal', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), nominal_cols),\n",
    "        ('scale', StandardScaler(), scale_cols),\n",
    "        ('passthrough', 'passthrough', passthrough_cols)\n",
    "    ])\n",
    "\n",
    "    # Full pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('feature_engineering', FeatureEngineer()),\n",
    "        ('preprocessing', preprocessor)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a72273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
      "       'DistanceFromHome', 'Education', 'EducationField',\n",
      "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',\n",
      "       'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
      "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'OverTime',\n",
      "       'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',\n",
      "       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
      "       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
      "       'YearsSinceLastPromotion', 'YearsWithCurrManager'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3ad9e",
   "metadata": {},
   "source": [
    "### Export pipeline\n",
    "\n",
    "We export the preprocessing pipeline unfitted here, so that we can fit in the next notebook on only the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750f4f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n",
      "       'Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender',\n",
      "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
      "       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
      "       'NumCompaniesWorked', 'OverTime', 'PercentSalaryHike',\n",
      "       'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',\n",
      "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
      "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
      "       'YearsWithCurrManager'],\n",
      "      dtype='object')\n",
      "Preprocessing pipeline saved.\n"
     ]
    }
   ],
   "source": [
    "# Fit on cleaned data (exclude target)\n",
    "df_clean = df.drop(columns='Attrition')\n",
    "print(df_clean.columns)\n",
    "pipeline = make_preprocessing_pipeline()\n",
    "\n",
    "# Save pipeline\n",
    "joblib.dump(pipeline, '../models/preprocessing_pipeline.pkl')\n",
    "print(\"Preprocessing pipeline saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2680ef",
   "metadata": {},
   "source": [
    "# **Preprocessing summary**\n",
    "\n",
    "This notebook:\n",
    "\n",
    "- Applies feature logic with `FeatureEngineer`\n",
    "- Encodes categorical features using `OrdinalEncoder` and `OneHotEncoder`\n",
    "- Scales numerical features with `StandardScaler`\n",
    "- Wraps everything into a reusable `Pipeline`\n",
    "\n",
    "This exported pipeline ensures consistent preprocessing across training and evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm-attrition-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
